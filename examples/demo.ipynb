{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python GenAI Demo\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab or Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from python_genai import LanguageModel, Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the API is available\n",
    "availability = await LanguageModel.availability()\n",
    "print(f\"Model availability: {availability}\")\n",
    "\n",
    "if availability == Availability.UNAVAILABLE:\n",
    "    print(\"\\n❌ Chrome Prompt API is not available.\")\n",
    "    print(\"Make sure you're running in Chrome with the API enabled.\")\n",
    "elif availability == Availability.DOWNLOADING:\n",
    "    print(\"\\n⏳ Model is downloading. Please wait and try again.\")\n",
    "elif availability == Availability.AVAILABLE:\n",
    "    print(\"\\n✅ API is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = await LanguageModel.params()\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.default_temperature}\")\n",
    "    print(f\"Max temperature: {params.max_temperature}\")\n",
    "    print(f\"Default top-K: {params.default_top_k}\")\n",
    "    print(f\"Max top-K: {params.max_top_k}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session\n",
    "session = await LanguageModel.create()\n",
    "\n",
    "# Send a prompt\n",
    "result = await session.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create({\n",
    "    \"initialPrompts\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful Python programming assistant who gives concise answers.\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First message\n",
    "result1 = await assistant_session.prompt(\"What is a list comprehension?\")\n",
    "print(\"Assistant:\", result1)\n",
    "print()\n",
    "\n",
    "# Follow-up message (the assistant remembers the context)\n",
    "result2 = await assistant_session.prompt(\"Can you show me an example?\")\n",
    "print(\"Assistant:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"positive\", \"negative\", \"neutral\"]\n",
    "        },\n",
    "        \"score\": {\n",
    "            \"type\": \"number\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await session.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema}\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create({\n",
    "    \"initialPrompts\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a creative storyteller.\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "result1 = await branch1.prompt(\"The dragon was friendly and helpful.\")\n",
    "print(\"Branch 1:\", result1)\n",
    "print()\n",
    "\n",
    "result2 = await branch2.prompt(\"The dragon was fierce and terrifying.\")\n",
    "print(\"Branch 2:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await session.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
